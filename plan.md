# StableGuard MVP â€” System Design

## Overview

A backyard MVP using a **desktop PC as the server** and **Raspberry Pi units as edge camera nodes** deployed across your yard. The goal is to prove the core detection pipeline end-to-end: capture video â†’ detect horses â†’ classify behaviour â†’ generate alerts.

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          YOUR YARD                                  â”‚
â”‚                                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚   â”‚  Pi Node 01  â”‚   â”‚  Pi Node 02  â”‚   â”‚  Pi Node 03  â”‚   ...    â”‚
â”‚   â”‚  (Stable)    â”‚   â”‚  (Field)     â”‚   â”‚  (Pen)       â”‚          â”‚
â”‚   â”‚              â”‚   â”‚              â”‚   â”‚              â”‚          â”‚
â”‚   â”‚ â€¢ Pi 4/5     â”‚   â”‚ â€¢ Pi 4/5     â”‚   â”‚ â€¢ Pi 4/5     â”‚          â”‚
â”‚   â”‚ â€¢ Pi Camera  â”‚   â”‚ â€¢ Pi Camera  â”‚   â”‚ â€¢ Pi Camera  â”‚          â”‚
â”‚   â”‚   Module v3  â”‚   â”‚   Module v3  â”‚   â”‚   Module v3  â”‚          â”‚
â”‚   â”‚ â€¢ IR LEDs    â”‚   â”‚ â€¢ IR LEDs    â”‚   â”‚ â€¢ IR LEDs    â”‚          â”‚
â”‚   â”‚ â€¢ Weatherproofâ”‚  â”‚ â€¢ Weatherproofâ”‚  â”‚ â€¢ Weatherproofâ”‚          â”‚
â”‚   â”‚   enclosure  â”‚   â”‚   enclosure  â”‚   â”‚   enclosure  â”‚          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚          â”‚                  â”‚                   â”‚                   â”‚
â”‚          â”‚       Wi-Fi (local network)          â”‚                   â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                             â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   DESKTOP SERVER   â”‚
                    â”‚   (Your PC)        â”‚
                    â”‚                    â”‚
                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚ â”‚ Ingestion API  â”‚ â”‚  â† receives frames/clips
                    â”‚ â”‚ (FastAPI)      â”‚ â”‚     from Pi nodes
                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â”‚         â”‚          â”‚
                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚ â”‚  CV Pipeline   â”‚ â”‚  â† YOLO detection,
                    â”‚ â”‚  (Python)      â”‚ â”‚     pose estimation,
                    â”‚ â”‚                â”‚ â”‚     behaviour classification
                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â”‚         â”‚          â”‚
                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚ â”‚  Analysis &    â”‚ â”‚  â† baseline tracking,
                    â”‚ â”‚  Alert Engine  â”‚ â”‚     anomaly scoring,
                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     colic risk engine
                    â”‚         â”‚          â”‚
                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚ â”‚  Database      â”‚ â”‚  â† SQLite / PostgreSQL
                    â”‚ â”‚  (events, logs)â”‚ â”‚
                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â”‚         â”‚          â”‚
                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚ â”‚  Web Dashboard â”‚ â”‚  â† local React/Flask UI
                    â”‚ â”‚  + Alert API   â”‚ â”‚     + push notifications
                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Breakdown

### 1. Edge Nodes (Raspberry Pi Units)

Each Pi acts as a dumb-ish camera node. For the MVP, keep processing minimal on the edge â€” let the server do the heavy lifting.

| Component | Recommendation | Notes |
|---|---|---|
| **Board** | Raspberry Pi 4 (4GB) or Pi 5 | Pi 5 preferred if you plan to do any on-device inference later |
| **Camera** | Pi Camera Module 3 (wide) | 120Â° FoV, autofocus, good low-light. Wide angle covers more of the stable |
| **Night vision** | Pi NoIR Camera + IR LED board | Or use Camera Module 3 + separate IR illuminator panel |
| **Enclosure** | IP65 weatherproof CCTV housing | Cheap on Amazon/eBay. Mount with adjustable bracket |
| **Power** | PoE hat + PoE switch, or weatherproof mains adapter | PoE is cleaner â€” single cable for power + network |
| **Storage** | 32GB microSD | Only needs OS + scripts; video streams to server |

**What each Pi does:**

- Captures frames at a configurable interval (e.g. 1 FPS for baseline, 5 FPS when motion detected)
- Runs lightweight motion detection locally (OpenCV frame differencing) to avoid flooding the network with static frames
- Sends JPEG frames or short H.264 clips to the server over HTTP/MQTT
- Reports health metrics (CPU temp, uptime, connectivity) to the server

**Software stack on the Pi:**

```
Raspberry Pi OS Lite (64-bit)
â”œâ”€â”€ picamera2          â€” camera control
â”œâ”€â”€ OpenCV (headless)  â€” motion detection
â”œâ”€â”€ MQTT client        â€” lightweight messaging to server
â””â”€â”€ systemd service    â€” auto-start on boot, watchdog restart
```

---

### 2. Network Layer

For a yard MVP, keep it simple:

| Approach | When to use |
|---|---|
| **Wi-Fi (2.4GHz)** | Pis within ~30m of your router. Cheapest option. |
| **Wi-Fi + mesh extender** | If field cameras are further out. A weatherproof mesh node extends range. |
| **Ethernet + PoE switch** | Most reliable. Run outdoor-rated Cat6 to each Pi. Power + data in one cable. |

**Protocol between Pi â†’ Server:**

- **MQTT** (via Mosquitto broker on the server) for lightweight event messages (motion detected, heartbeat, metadata)
- **HTTP POST** (to FastAPI on the server) for frame/clip uploads â€” simpler to debug in MVP than streaming protocols
- **Alternative for later:** RTSP streaming if you want continuous video, but overkill for MVP

---

### 3. Server (Desktop PC)

This is the brain. Your desktop handles all the compute-intensive CV and ML work.

**Minimum specs for MVP:**

| Resource | Minimum | Ideal |
|---|---|---|
| **CPU** | Modern quad-core (i5/Ryzen 5) | 8+ cores for parallel processing |
| **RAM** | 16GB | 32GB if running multiple camera feeds |
| **GPU** | NVIDIA GTX 1060 / RTX 2060+ | Any CUDA-capable GPU massively accelerates YOLO inference |
| **Storage** | 500GB SSD | 1TB+ if retaining video clips for training data |
| **OS** | Ubuntu 22.04 / 24.04 LTS | Easiest for Python ML stack + Docker |

---

### 4. Server Software Architecture

```
Desktop Server
â”‚
â”œâ”€â”€ /ingestion                    â† Receives data from Pi nodes
â”‚   â”œâ”€â”€ FastAPI app               â€” HTTP endpoint for frame uploads
â”‚   â”œâ”€â”€ MQTT subscriber           â€” Listens for motion events, heartbeats
â”‚   â””â”€â”€ Frame buffer / queue      â€” Redis or in-memory queue
â”‚
â”œâ”€â”€ /detection                    â† Computer vision pipeline
â”‚   â”œâ”€â”€ Horse detector            â€” YOLOv8/v11 trained on horse dataset
â”‚   â”œâ”€â”€ Horse re-ID module        â€” Identify individual horses (MVP: colour/marking heuristics)
â”‚   â”œâ”€â”€ Pose estimator            â€” Detect posture: standing, lying, rolling
â”‚   â”œâ”€â”€ Behaviour classifier      â€” Classify: eating, drinking, pawing, pacing, etc.
â”‚   â””â”€â”€ Object detector           â€” Detect: rugs, water troughs, hay, droppings
â”‚
â”œâ”€â”€ /analysis                     â† Intelligence layer
â”‚   â”œâ”€â”€ Baseline engine           â€” Per-horse behavioural baselines (rolling averages)
â”‚   â”œâ”€â”€ Anomaly scorer            â€” Deviation from baseline â†’ risk score
â”‚   â”œâ”€â”€ Colic risk engine         â€” Multi-factor scoring (rolling + not eating + pacing etc.)
â”‚   â””â”€â”€ Alert generator           â€” Amber / Red / Critical classification
â”‚
â”œâ”€â”€ /storage                      â† Data persistence
â”‚   â”œâ”€â”€ PostgreSQL / SQLite       â€” Events, baselines, horse profiles, alert history
â”‚   â”œâ”€â”€ File storage              â€” Saved clips and snapshots (evidence for alerts)
â”‚   â””â”€â”€ Time-series store         â€” Optional: InfluxDB for metrics (activity levels over time)
â”‚
â”œâ”€â”€ /api                          â† Backend API
â”‚   â””â”€â”€ FastAPI / Flask           â€” REST API serving the dashboard and mobile app
â”‚
â””â”€â”€ /dashboard                    â† Frontend
    â””â”€â”€ React app (or simple      â€” Live camera views, alert feed, horse profiles,
        Flask templates)             historical charts, colic risk panel
```

---

### 5. CV / ML Pipeline Detail

This is the core of StableGuard. Here's how to approach it for MVP:

#### Stage 1 â€” Horse Detection

- **Model:** YOLOv8n or YOLOv11n (nano variants â€” fast, accurate enough)
- **Training data:** Start with COCO pre-trained weights (horses are a COCO class). Fine-tune on your own horses with ~200-500 labelled images from your yard cameras.
- **Output:** Bounding boxes around each horse in frame

#### Stage 2 â€” Horse Identification (Re-ID)

For MVP, keep this simple:

- **Approach 1 (easiest):** If you have one horse per camera (e.g. individual stables), just assign identity by camera location
- **Approach 2 (moderate):** Use colour histograms + marking templates. Crop the detected horse, extract dominant colours, compare against enrolled profiles
- **Approach 3 (later):** Train a re-identification embedding network (triplet loss) on your horses

#### Stage 3 â€” Posture / Behaviour Classification

- **Pose estimation:** Use a keypoint model (YOLOv8-pose fine-tuned on horses, or a custom DeepLabCut model) to get body landmark positions
- **Classification:** A simple rule-based classifier to start:
  - Horse bounding box aspect ratio wide + low â†’ **lying down**
  - Keypoints show head near ground â†’ **eating/grazing**
  - Repeated lateral rolling motion â†’ **rolling**
  - Head turned toward flank â†’ **flank-watching**
  - High step frequency, small displacement â†’ **pawing**
  - High displacement over time â†’ **pacing**
- **Later:** Replace rules with a trained temporal classifier (LSTM or Transformer on keypoint sequences)

#### Stage 4 â€” Object Detection (Environment)

- Fine-tune YOLO to also detect: water troughs, hay nets, feed buckets, droppings, rugs
- This can be a single model with horse + environment classes, or a separate lightweight model

---

### 6. Alert & Baseline System

```
  Per-Horse Data Flow:
  
  Raw detections (every frame)
       â”‚
       â–¼
  Rolling aggregation (5-min windows)
       â”‚
       â–¼
  Behavioural state log
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Horse: Bella                     â”‚
  â”‚ 22:00-22:05: Standing (resting)  â”‚
  â”‚ 22:05-22:10: Lying (lateral)     â”‚
  â”‚ 22:10-22:12: Rolling (Ã—3)        â”‚
  â”‚ 22:12-22:15: Standing (agitated) â”‚
  â”‚ 22:15-22:20: Pawing              â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
  Baseline comparison
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Bella's 7-day avg at this hour:  â”‚
  â”‚ â€¢ Lying: 40min/hr                â”‚
  â”‚ â€¢ Rolling: 0.5Ã—/hr              â”‚
  â”‚ â€¢ Pawing: 0Ã—/hr                 â”‚
  â”‚                                  â”‚
  â”‚ Current hour:                    â”‚
  â”‚ â€¢ Rolling: 3Ã—  â† 6Ã— baseline âš   â”‚
  â”‚ â€¢ Pawing: YES  â† unusual     âš   â”‚
  â”‚ â€¢ Not eaten for 2hrs         âš   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
  Colic Risk Score: 7.2 / 10  â†’  ğŸ”´ RED ALERT
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Alert: Colic risk â€” Bella        â”‚
  â”‚ Severity: RED                    â”‚
  â”‚ Factors:                         â”‚
  â”‚  â€¢ Repeated rolling (3Ã— in 10m) â”‚
  â”‚  â€¢ Pawing behaviour detected     â”‚
  â”‚  â€¢ No feeding observed (2hrs)    â”‚
  â”‚ Action: Check horse immediately  â”‚
  â”‚ Clip: [30s video attached]       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Alert delivery for MVP:**

- Web dashboard notification (WebSocket push)
- Email alert (SMTP â€” easy to set up)
- SMS via Twilio API (cheap, reliable)
- Later: mobile push notifications via a proper app

---

### 7. Data Model (Simplified)

```sql
-- Core entities
horses (id, name, profile_photo, enrolled_date, notes)
cameras (id, location_name, pi_hostname, ip_address, status)
camera_horse_assignments (camera_id, horse_id)  -- which horse is where

-- Detection events
detections (
    id, timestamp, camera_id, horse_id,
    bbox_x, bbox_y, bbox_w, bbox_h,
    confidence, frame_path
)

-- Behavioural states (aggregated from detections)
behaviour_logs (
    id, horse_id, start_time, end_time,
    behaviour_type,  -- standing, lying, rolling, eating, drinking, pawing, pacing, flank_watching
    confidence, metadata_json
)

-- Baselines (computed daily)
baselines (
    id, horse_id, hour_of_day, day_type,  -- weekday/weekend
    avg_standing_mins, avg_lying_mins, avg_eating_mins,
    avg_rolling_count, avg_dropping_count,
    computed_date
)

-- Alerts
alerts (
    id, horse_id, timestamp, severity,  -- amber, red, critical
    alert_type,  -- colic_risk, inactivity, excessive_movement, etc.
    risk_score, contributing_factors_json,
    clip_path, acknowledged, acknowledged_by
)

-- Environment readings
environment_logs (
    id, camera_id, timestamp,
    water_trough_level, hay_present, dropping_count,
    rug_detected, rug_type, ambient_temp
)
```

---

### 8. Tech Stack Summary

| Layer | Technology | Why |
|---|---|---|
| **Edge OS** | Raspberry Pi OS Lite (64-bit) | Minimal, headless, stable |
| **Edge capture** | picamera2 + OpenCV | Native Pi camera support + motion detection |
| **Messaging** | MQTT (Mosquitto) | Lightweight pub/sub, perfect for IoT |
| **Frame transport** | HTTP POST (FastAPI) | Simple, debuggable, good enough for MVP |
| **Server OS** | Ubuntu 22.04/24.04 | Best Linux ML ecosystem support |
| **CV/ML** | YOLOv8/v11 (Ultralytics), PyTorch | State-of-the-art detection, huge community |
| **API** | FastAPI (Python) | Async, fast, auto-docs, great for ML serving |
| **Database** | SQLite (MVP) â†’ PostgreSQL (scale) | Zero-config start, easy migration later |
| **Time-series** | InfluxDB (optional) | If you want rich activity-over-time queries |
| **Dashboard** | React + Vite (or Flask templates) | React for rich interactivity; Flask templates if you want faster MVP |
| **Alerts** | SMTP + Twilio | Email + SMS, easy to wire up |
| **Containers** | Docker Compose | Bundle server services, reproducible setup |
| **Model training** | Label Studio + Ultralytics CLI | Open-source labelling â†’ YOLO training loop |

---

### 9. MVP Build Phases

#### Phase 1 â€” Camera + Capture (Week 1-2)

- Set up Pi with camera module, get frames streaming
- Implement motion detection on Pi (OpenCV frame diff)
- Set up MQTT broker on server
- Pi sends motion events + frames to server
- Verify: frames arrive and are stored on the server

#### Phase 2 â€” Horse Detection (Week 3-4)

- Install YOLOv8 on server with CUDA
- Run pre-trained COCO model â€” verify horse detections on your frames
- Collect ~200 images from your cameras, label with Label Studio
- Fine-tune YOLO on your yard data
- Verify: bounding boxes reliably track your horses

#### Phase 3 â€” Behaviour Classification (Week 5-7)

- Implement posture classification (rule-based on bbox aspect ratio + keypoints)
- Detect: standing, lying, rolling, eating
- Log behavioural states to database
- Build baseline aggregation (rolling 7-day averages per horse per hour)
- Verify: behaviour logs look sensible over 48hrs of data

#### Phase 4 â€” Alert Engine (Week 8-9)

- Implement colic risk scoring (multi-factor weighted score)
- Set alert thresholds (amber/red/critical)
- Wire up email alerts via SMTP
- Save 30-second evidence clips when alerts fire
- Verify: simulate colic-like patterns, confirm alerts fire correctly

#### Phase 5 â€” Dashboard (Week 10-12)

- Build simple web UI: live camera view, alert feed, horse profiles
- Show behavioural timelines per horse (bar chart of daily activity)
- Display current colic risk scores
- Allow alert acknowledgement
- Verify: usable daily by you to monitor your horses

---

### 10. Directory Structure (Server)

```
stableguard/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”‚
â”œâ”€â”€ edge/                          # Code deployed to Raspberry Pis
â”‚   â”œâ”€â”€ capture.py                 # Camera capture + motion detection
â”‚   â”œâ”€â”€ transport.py               # MQTT + HTTP frame upload
â”‚   â”œâ”€â”€ config.yaml                # Camera-specific settings
â”‚   â””â”€â”€ install.sh                 # Pi setup script
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ api.py                 # FastAPI frame upload endpoint
â”‚   â”‚   â””â”€â”€ mqtt_listener.py       # MQTT event subscriber
â”‚   â”‚
â”‚   â”œâ”€â”€ detection/
â”‚   â”‚   â”œâ”€â”€ horse_detector.py      # YOLO horse detection
â”‚   â”‚   â”œâ”€â”€ horse_reid.py          # Individual identification
â”‚   â”‚   â”œâ”€â”€ pose_estimator.py      # Keypoint / posture estimation
â”‚   â”‚   â”œâ”€â”€ behaviour_classifier.py # Rule-based behaviour classification
â”‚   â”‚   â””â”€â”€ environment_detector.py # Rugs, troughs, droppings
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ baseline_engine.py     # Per-horse rolling baselines
â”‚   â”‚   â”œâ”€â”€ anomaly_scorer.py      # Deviation scoring
â”‚   â”‚   â”œâ”€â”€ colic_engine.py        # Multi-factor colic risk
â”‚   â”‚   â””â”€â”€ alert_generator.py     # Alert classification + dispatch
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ models.py              # SQLAlchemy / DB models
â”‚   â”‚   â”œâ”€â”€ migrations/            # Alembic migrations
â”‚   â”‚   â””â”€â”€ clip_manager.py        # Save / prune evidence clips
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py                # FastAPI app
â”‚   â”‚   â”œâ”€â”€ routes/                # REST endpoints
â”‚   â”‚   â””â”€â”€ websocket.py           # Live dashboard push
â”‚   â”‚
â”‚   â””â”€â”€ dashboard/
â”‚       â”œâ”€â”€ src/                   # React app
â”‚       â””â”€â”€ public/
â”‚
â”œâ”€â”€ models/                        # Trained model weights
â”‚   â”œâ”€â”€ yolo_horse_v1.pt
â”‚   â””â”€â”€ pose_horse_v1.pt
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ frames/                    # Raw captured frames
â”‚   â”œâ”€â”€ clips/                     # Alert evidence clips
â”‚   â””â”€â”€ training/                  # Labelled training data
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ train_detector.py          # YOLO fine-tuning script
    â”œâ”€â”€ label_export.py            # Label Studio â†’ YOLO format
    â””â”€â”€ setup_pi.sh                # Automated Pi provisioning
```

---

### 11. Key Risks & Mitigations (MVP)

| Risk | Impact | Mitigation |
|---|---|---|
| **Wi-Fi dropout to field cameras** | Missed detections | Buffer frames on Pi SD card; upload when reconnected. Consider PoE for critical cameras. |
| **Night-time image quality** | Poor detections in darkness | IR illuminator + NoIR camera. Test and adjust IR LED power. |
| **False positive alerts** | Alert fatigue, loss of trust | Conservative alert thresholds in MVP. Require multiple concurrent signals before firing. |
| **Horse Re-ID inaccuracy** | Wrong horse assigned behaviours | MVP: one horse per camera zone. Later: improve with embedding model. |
| **GPU bottleneck** | Can't process all cameras in real-time | Reduce FPS per camera; stagger processing; prioritise cameras with motion events. |
| **Weatherproofing failures** | Dead Pi nodes | IP65 enclosure + silicone seal. Check regularly. Have a spare Pi ready. |
| **Model drift** | Accuracy degrades over time (seasons, lighting) | Periodic re-labelling + re-training. Log confidence scores and review low-confidence detections. |

---

### 12. Future Enhancements (Post-MVP)

- **Cloud deployment** â€” move inference and dashboard to AWS/GCP for multi-yard support
- **Mobile app** â€” native iOS/Android with push notifications
- **On-device inference** â€” run lightweight models on Pi 5 / Coral TPU for lower latency
- **Audio detection** â€” add microphones for vocalisation analysis (distress calls, coughing)
- **Multi-camera tracking** â€” track a horse moving between field â†’ stable â†’ arena
- **Vet integration** â€” share reports directly with veterinary practice management systems
- **Insurance API** â€” provide monitoring evidence to equine insurers
- **Temperature sensors** â€” DHT22 / BME280 on each Pi for ambient conditions
f