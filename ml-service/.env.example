# Model identifiers â€” change these to swap models, then restart the service.
# Point to any HuggingFace model ID or a local path to your trained model.
VLM_MODEL_ID=Qwen/Qwen2-VL-2B-Instruct
EMBED_MODEL_ID=google/siglip-so400m-patch14-384

# Device: cuda, cpu, or auto (auto selects cuda if available)
DEVICE=auto

# Set to true to skip model loading entirely (useful for frontend/backend dev without GPU)
MOCK_MODE=false

# Optional: HuggingFace token for gated or private models
HF_TOKEN=

# Host/port (used when running with uvicorn directly)
HOST=0.0.0.0
PORT=8001
